{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series forecasting with sktime\n",
    "Estimated time: 40 min"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/tasks-forecasting.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quickstart\n",
    "- Univariate forecasting\n",
    "    - With statistical models\n",
    "    - With machine learning models\n",
    "    - Model evaluation and selection\n",
    "- Univariate forecasting with exogenous data\n",
    "- Multivariate forecasting\n",
    "- Probabilistic forecasting\n",
    "- Hierarchical forecasting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* typical business use case :-)\n",
    "* here's some monthly historic sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_shampoo_sales\n",
    "from sktime.utils.plotting import plot_series\n",
    "\n",
    "y = load_shampoo_sales()\n",
    "\n",
    "fig, ax = plot_series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "\n",
    "y_train, y_test = temporal_train_test_split(y=y, test_size=6)\n",
    "fig, ax = plot_series(y_train, y_test, labels=[\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.arima import AutoARIMA\n",
    "\n",
    "# 1) Define the model\n",
    "forecaster = AutoARIMA(suppress_warnings=True)\n",
    "\n",
    "# 2) Fit on train data\n",
    "forecaster.fit(y_train)\n",
    "\n",
    "# 3) Use fitted model to predict for a certain forecast horizon (fh)\n",
    "fh = [1, 2, 3, 4, 5, 6] # Relative to y_train\n",
    "y_pred = forecaster.predict(fh)\n",
    "\n",
    "fig, ax = plot_series(y_train, y_test, y_pred, labels=[\"train\", \"test\", \"pred\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* scoring using `sktime` performance metrics\n",
    "* requires forecasts & true values as `sktime` compatible time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import MeanAbsolutePercentageError\n",
    "\n",
    "smape = MeanAbsolutePercentageError(symmetric=True)\n",
    "\n",
    "print(f\"AutoARIMA - sMAPE error: {smape(y_test, y_pred):.1%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* MAPE just for illustration - not always best choice\n",
    "* for robust evaluation & comparison, use backtesting (not single train/test split)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate forecasting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "showcase common approaches for forecasting univariate time series in `sktime`:\n",
    "- Classical statistical models (e.g., econometric, ARIMA, etc)\n",
    "- Machine learning models (e.g., direct/recursive reduction)\n",
    "\n",
    "Recommendation: try simple models and naive baselines first!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical forecasting method example: `AutoETS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.ets import AutoETS\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "\n",
    "forecasters = [AutoETS(auto=True), ThetaForecaster()]\n",
    "\n",
    "for forecaster in forecasters:\n",
    "    y_pred = forecaster.fit_predict(y=y_train, fh=fh)\n",
    "    title = (\n",
    "        f\"{str(forecaster).split('(')[0]} - sMAPE error: {smape(y_test, y_pred):.1%}\"\n",
    "    )\n",
    "    fig, ax = plot_series(\n",
    "        y_train, y_test, y_pred, labels=[\"train\", \"test\", \"pred\"], title=title\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out all other sktime forecasting algorithms [in the documentation](https://www.sktime.net/en/latest/api_reference/forecasting.html) or by running the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"forecaster\", as_dataframe=True, suppress_import_stdout=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting with ML algorithms (reduction)\n",
    "\n",
    "- uses sklearn regressor on tabulated data to forecast\n",
    "- plug & play any sklearn compatible regressor, e.g., lightgbm or xgboost\n",
    "- important: forecasting != regression\n",
    "\n",
    "Estimator does this internally:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/tabularization.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in unified forecasting interface! No need to handle `sklearn` directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "\n",
    "# Can be swapped with XBGoost, LightGBM, CatBoost, etc.\n",
    "regressor = HistGradientBoostingRegressor()\n",
    "\n",
    "# Create a forecaster from the tabular regressor by wrapping it in `make_reduction`\n",
    "forecaster = make_reduction(regressor, strategy=\"direct\", window_length=16)\n",
    "\n",
    "y_pred = forecaster.fit_predict(y=y_train, fh=fh)\n",
    "title = f\"Gradient-boosted tree regressor - sMAPE error: {smape(y_test, y_pred):.1%}\"\n",
    "fig, ax = plot_series(\n",
    "    y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"], title=title\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... this is bad! Why?\n",
    "\n",
    "Subtle:\n",
    "\n",
    "- Gradient boosting trees cannot \"extrapolate\"\n",
    "- only forecast well within their observed range\n",
    "\n",
    "Solution: make (more) stationary by differencing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "easy to do in `sktime`: transformers (= transformation estimators)\n",
    "\n",
    "(note: wider concept than deep learn transformers, includes simple trafos too)\n",
    "\n",
    "Let's see how to use the `Differencer` transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.difference import Differencer\n",
    "\n",
    "transformer = Differencer(lags=1)\n",
    "y_transform = transformer.fit_transform(y)\n",
    "fig, ax = plot_series(\n",
    "    y, y_transform, labels=[\"y\", \"y_diff\"], title=\"Difference transformation\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers composable with forecasters, plug together to forecaster!\n",
    "\n",
    "here: plug `Differencer` into tree-based reduction forecaster, via `*` dunder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = HistGradientBoostingRegressor()\n",
    "forecaster = make_reduction(regressor, strategy=\"direct\", window_length=16)\n",
    "forecaster_with_differencer = Differencer(lags=1) * forecaster\n",
    "\n",
    "y_pred = forecaster_with_differencer.fit_predict(y=y_train, fh=fh)\n",
    "title = f\"Gradient-boosted tree regressor with difference transform - sMAPE error: {smape(y_test, y_pred):.1%}\"\n",
    "fig, ax = plot_series(\n",
    "    y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"], title=title\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on transformers and composition later!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation and selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best practice for model evaluation: backtesting, sliding window\n",
    "\n",
    "(not single split MAPE etc...)\n",
    "\n",
    "how this works:\n",
    "\n",
    "* define backtesting schema using cross-validation splitter\n",
    "* simple workflows: use `evaluate` all-in-one evaluator\n",
    "* customizable: use benchmarking module for experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Window splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import ExpandingWindowSplitter\n",
    "from sktime.utils.plotting import plot_windows\n",
    "\n",
    "cv = ExpandingWindowSplitter(initial_window=24, fh=fh, step_length=2)\n",
    "n_folds = cv.get_n_splits(y)\n",
    "plot_windows(cv, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backtesting for single model evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can leverage this more rebust cross-validation strategies for sinlge model evaluation by using `sktime`'s evaluat function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_evaluation import evaluate\n",
    "from sktime.performance_metrics.forecasting import MeanSquaredError\n",
    "\n",
    "forecaster = forecaster_with_differencer.clone()\n",
    "scorers = [smape, MeanSquaredError(square_root=True)]\n",
    "backtest = evaluate(\n",
    "    forecaster=forecaster, y=y, cv=cv, scoring=scorers, return_data=True\n",
    ")\n",
    "backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest.loc[0, \"y_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_series(\n",
    "    y,\n",
    "    *tuple(backtest[\"y_pred\"][i] for i in range(n_folds)),\n",
    "    labels=[\"y\"] + [f\"fold_{i}\" for i in range(n_folds)],\n",
    "    title=f\"Backtest predictions, average sMAPE: {backtest['test_MeanAbsolutePercentageError'].mean():.1%}\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced benchmarking via `ForecastingBenchmark`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* group of models in same benchmark scenario\n",
    "* flexible set-up, e.g., splitters, evaluation metrics\n",
    "\n",
    "Note: requires soft dependency [`kotsu`](https://github.com/datavaluepeople/kotsu) installed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start: create `ForecastingBenchmark` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.benchmarking.forecasting import ForecastingBenchmark\n",
    "\n",
    "benchmark = ForecastingBenchmark()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2: add models with `add_estimator` method.\n",
    "\n",
    "Example: `NaiveForecaster` as simple benchmark model.\n",
    "\n",
    "Good idea to assess baseline prediction accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "\n",
    "benchmark.add_estimator(\n",
    "    estimator=NaiveForecaster(strategy=\"mean\", window_length=3),\n",
    "    estimator_id=\"Naive-mean-3-v1\",\n",
    ")\n",
    "benchmark.add_estimator(estimator=AutoARIMA(), estimator_id=\"AutoARIMA-v1\")\n",
    "benchmark.add_estimator(estimator=AutoETS(auto=True), estimator_id=\"AutoETS-v1\")\n",
    "benchmark.add_estimator(\n",
    "    estimator=forecaster_with_differencer.clone(), estimator_id=\"LightGBM-v1\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next - define backtest strategy `cv`, define forecasting tasks & scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ExpandingWindowSplitter(initial_window=24, fh=fh, step_length=2)\n",
    "scorers = [smape]\n",
    "\n",
    "benchmark.add_task(\n",
    "    load_shampoo_sales,\n",
    "    cv,\n",
    "    scorers,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`run` to start benchmarking, this will now compute results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = benchmark.run(output_file=\"results.csv\")\n",
    "results_df.set_index(\"model_id\").iloc[:, -2:].style.format(\"{:.1%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently in active development! (summer programme)\n",
    "\n",
    "- Open to feedback\n",
    "- Welcome and appreciate contributions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate forecasting with exogenous data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exogeneous data = other related time series that can improve prediction\n",
    "- Example: information about promotions when forecasting sales (promotions drive sales)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the same sales data we have been working on before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_shampoo_sales\n",
    "\n",
    "y = load_shampoo_sales()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the sales data, noise and some simple transformations to create *fake* promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sktime.utils.plotting import plot_series\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "\n",
    "# Use a differencer, clipping and some noise to generate fake promotional data\n",
    "transformer = Differencer(lags=1)\n",
    "y_transform = transformer.fit_transform(y)\n",
    "noise = np.random.RandomState(seed=93).normal(0, 100, np.shape(y))\n",
    "X_promo = (y_transform + noise).clip(lower=0)\n",
    "\n",
    "fig, ax = plot_series(\n",
    "    y, X_promo, labels=[\"y\", \"fake_promotions\"], title=\"Sales and Promotions\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split both the target time series (y: sales) and the exogenous time series (X: promotions) with the `temporal_train_test_split` we have used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "\n",
    "fh = [1, 2, 3, 4]\n",
    "y_train, y_test, X_train, X_test = temporal_train_test_split(\n",
    "    y=y, X=X_promo, test_size=len(fh)\n",
    ")\n",
    "\n",
    "fig, ax = plot_series(\n",
    "    y_train,\n",
    "    X_train,\n",
    "    y_test,\n",
    "    X_test,\n",
    "    labels=[\"y_train\", \"X_train\", \"y_train\", \"X_test\"],\n",
    "    title=\"Test and train: sales and promotions\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can forecast y (sales) also using the known values of future X (promotions) by passing the future X data in the predict step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.arima import AutoARIMA\n",
    "\n",
    "forecaster = AutoARIMA(suppress_warnings=True)\n",
    "\n",
    "# Use train data in fit\n",
    "forecaster.fit(y=y_train, X=X_train, fh=fh)\n",
    "\n",
    "# Note how the \"future\" data of X is passed in the predict step\n",
    "y_pred = forecaster.predict(X=X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the prediction looks like when adding promotional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import MeanAbsolutePercentageError\n",
    "\n",
    "smape = MeanAbsolutePercentageError(symmetric=True)\n",
    "\n",
    "title = f\"AutoARIMA with promotional data - sMAPE error: {smape(y_test, y_pred):.1%}\"\n",
    "fig, ax = plot_series(\n",
    "    y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"], title=title\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: as we created the promotions from the sales data, the performance upflift is over-optimistic (data leakage)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if don't have future promotional data?\n",
    "\n",
    "If we believe that we can forecast `X` (promotions) independently of `y` (sales) we can use these predictions of `X` to inform the predictions of `y`.\n",
    "\n",
    "Here, we decide to use a different model for `X` than for `y`:\n",
    "- y (sales): AutoARIMA\n",
    "- X (promotion): Croston - due to intermittency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.compose import ForecastX\n",
    "from sktime.forecasting.croston import Croston\n",
    "\n",
    "forecaster_X = ForecastX(\n",
    "    forecaster_y=AutoARIMA(suppress_warnings=True),\n",
    "    forecaster_X=Croston(),\n",
    ")\n",
    "forecaster_X.fit(y=y, X=X_promo, fh=fh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting on both `X` and `y` we can creat predictions of `y` directly. Under the hood `sktime` is forecasting `X` with the `Croston()` model and using it in the prediction step of `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now in the `predict` step we don't need to pass X\n",
    "y_pred = forecaster_X.predict(fh=fh)\n",
    "\n",
    "title = f\"ForecastX: Using AutoARIMA for y (sales) and Croston for X (promotions)\"\n",
    "fig, ax = plot_series(\n",
    "    y, y_pred, labels=[\"y\", \"y_pred\"], title=title\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sometimes, the focus is not on a single univariate time series, but rather on forecasting a group of time series that represent different aspects of a single entity.\n",
    "- Example: forecasting multiple macroeconomic indicators that collectively measure \"the economy\".\n",
    "\n",
    "Let's explore how `sktime` enables multivariate forecasting for this use-case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate forecasting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset: multiple macroecon indicators, reported yearly (\"Longley dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_longley\n",
    "\n",
    "_, y = load_longley()\n",
    "\n",
    "y = y.drop(columns=[\"UNEMP\", \"ARMED\", \"POP\"])\n",
    "\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some forecasters, e.g., `VAR` are genuinely mutltivariate.\n",
    "\n",
    "Let's predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.var import VAR\n",
    "\n",
    "forecaster = VAR()\n",
    "forecaster.fit(y, fh=[1, 2, 3])\n",
    "\n",
    "y_pred = forecaster.predict()\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multivariate/univariate is visible and searchable via tags,\n",
    "\n",
    "e.g., `get_tags` to display properties of forecaster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.get_tags()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But also all univariate forecasters can natively forecast multivariate data!\n",
    "\n",
    "This is done by \"broadcasting\" across variables.\n",
    "\n",
    "`ARIMA` is a purely univariate model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_longley\n",
    "from sktime.forecasting.arima import ARIMA\n",
    "\n",
    "_, y = load_longley()\n",
    "\n",
    "y = y.drop(columns=[\"UNEMP\", \"ARMED\", \"POP\"])\n",
    "\n",
    "forecaster = ARIMA()\n",
    "forecaster.fit(y, fh=[1, 2, 3])\n",
    "\n",
    "forecaster.forecasters_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sktime` fits one single `ARIMA` model per variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags tell us that `ARIMA` is univariate, using `get_tags`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.get_tags()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Point predictions are often not enough!\n",
    "- forecasts inherently contain some level of uncertainty\n",
    "- important to estimate that uncertainty, \"probabilistic predictions\"\n",
    "- example: uncertainty range from prediction intervals\n",
    "\n",
    "`sktime` can make multiple types of probabilistic predictions\n",
    "\n",
    "1st example: prediction intervals via `predict_interval`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_shampoo_sales\n",
    "\n",
    "y = load_shampoo_sales()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.ets import AutoETS\n",
    "\n",
    "# 1) Define the model\n",
    "forecaster = AutoETS(auto=True)\n",
    "\n",
    "# 2) Fit on train data\n",
    "forecaster.fit(y_train)\n",
    "\n",
    "# 3) Use fitted model to predict for a certain forecast horizon (fh)\n",
    "fh = [1, 2, 3, 4]\n",
    "y_pred = forecaster.predict(fh)\n",
    "\n",
    "# 4) Call a probabilistic method after or in place of step 3\n",
    "y_pred_int = forecaster.predict_interval(coverage=0.95)\n",
    "\n",
    "fig, ax = plot_series(\n",
    "    y_train, y_test, y_pred, labels=[\"train\", \"test\", \"pred\"], pred_interval=y_pred_int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_int"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods available for all probabilistic forecasters:\n",
    "\n",
    "- `predict_interval` produces interval forecasts.\n",
    "  Argument `coverage` (nominal interval coverage) must be provided.\n",
    "- `predict_quantiles` produces quantile forecasts.\n",
    "  Argument `alpha` (quantile values) must be provided.\n",
    "- `predict_var` produces variance forecasts. Same args as `predict`.\n",
    "- `predict_proba` produces full distributional forecasts. Same args as `predict`.\n",
    "\n",
    "| Name | param | prediction/estimate of | `sktime` |\n",
    "| ---- | ----- | ---------------------- | -------- |\n",
    "| point forecast | | conditional expectation $\\mathbb{E}[y'\\|y]$ | `predict` |\n",
    "| variance forecast | | conditional variance $Var[y'\\|y]$ | `predict_var` |\n",
    "| quantile forecast | $\\alpha\\in (0,1)$ | $\\alpha$-quantile of $y'\\|y$ | `predict_quantiles` |\n",
    "| interval forecast | $c\\in (0,1)$| $[a,b]$ s.t. $P(a\\le y' \\le b\\| y) = c$ | `predict_interval` |\n",
    "| distribution forecast | | the law/distribution of $y'\\|y$ | `predict_proba` |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`all_estimators` use to list all forecasters capable of proba predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\n",
    "    \"forecaster\",\n",
    "    filter_tags={\"capability:pred_int\": True},\n",
    "    as_dataframe=True,\n",
    "    suppress_import_stdout=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  estimators with`pred_int` tag always all probabilistic methods available - either all of them or none."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenting different proba methods and their outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.predict_interval(coverage=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.predict_quantiles(alpha=[0.275, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.predict_var()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict full predictive distributions, `predict_proba` can be used. This returns a `BaseDistribution` child instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.predict_proba()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical forecasting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/hierarchy.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider hierarchical dataframe of historical monthly sales in different categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odsc_utils import load_product_hierarchy\n",
    "\n",
    "y = load_product_hierarchy()\n",
    "\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pick a specific date to clearly see the hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiindex slicing can become important when using hierarchical data!\n",
    "y.loc[(slice(None), slice(None), \"2000-01\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the different time series in the hierarchy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_index = y.droplevel(-1).index.unique()\n",
    "fig, ax = plot_series(*(y.loc[idx] for idx in product_index), labels=product_index, title=\"Product sales\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sktime` broadcasts all non-hierarchical forecasters to hierarchical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.ets import AutoETS\n",
    "\n",
    "forecaster = AutoETS(auto=True)\n",
    "\n",
    "y_pred = forecaster.fit_predict(y, fh=[1])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.forecasters_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For hierarchies, often want forecasts of aggregated levels.\n",
    "\n",
    "Instead of manually summing up,\n",
    "\n",
    "we can use `Aggregator` transformer in `sktime`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.hierarchical.aggregate import Aggregator\n",
    "\n",
    "y_hier = Aggregator().fit_transform(y)\n",
    "\n",
    "y_hier.loc[(slice(None), slice(None), \"2000-01\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = AutoETS(auto=True, random_state=0)\n",
    "\n",
    "y_hier_pred = forecaster.fit_predict(y_hier, fh=1)\n",
    "y_hier_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare top level and the sum of the bottom level forecasts...\n",
    "\n",
    "... they do not add up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "584.481241 - (119.460419 + 169.749332 + 146.466778 + 139.583316)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why? Independent instances of forecaster fitted per level,\n",
    "\n",
    "no constraint to ensure the predictions add up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.forecasters_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `ReconcilerForecaster` to enfore hierarchical reconciliation (= level forecasts add up)\n",
    "\n",
    "`ReconcilerForecaster` takes a forecaster and adds reconciliation logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.reconcile import ReconcilerForecaster\n",
    "\n",
    "reconciler_forecaster = ReconcilerForecaster(\n",
    "    forecaster=forecaster.clone(), method=\"bu\"\n",
    ")\n",
    "\n",
    "y_hier_pred = reconciler_forecaster.fit_predict(y_hier, fh=1)\n",
    "y_hier_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now top/bottom forecasts add up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "575.259845 - (119.460419 + 169.749332 + 146.466778 + 139.583316)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available reconciliation in docstring or `METHOD_LIST`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valid reconciliation methods:\")\n",
    "for method in ReconcilerForecaster.METHOD_LIST:\n",
    "    print(f\"- {method}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HierarchyEnsembleForecaster` to customize forecasters at different hierarchy levels/nodes.\n",
    "\n",
    "Forecasters built this way also aggregate the hierachical data for you under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odsc_utils import load_product_hierarchy\n",
    "\n",
    "y = load_product_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.compose import HierarchyEnsembleForecaster\n",
    "from sktime.forecasting.arima import AutoARIMA\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "\n",
    "forecasters = [\n",
    "    ('Auto ARIMA', AutoARIMA(), 0),\n",
    "    ('Auto ETS', AutoETS(auto=True), 1)\n",
    "]\n",
    "\n",
    "forecaster = HierarchyEnsembleForecaster(\n",
    "                forecasters=forecasters,\n",
    "                by='level', default = AutoETS(auto=True)\n",
    ")\n",
    "\n",
    "y_pred = forecaster.fit_predict(y, fh=[1])\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now, all forecasts \"per group\"...\n",
    "\n",
    "- Local: fit a model to each time series locally\n",
    "- Global: fit a single model to all the series - below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global forecasting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of global forecasting:\n",
    "- The model has access to more data to learn from, great when individual time series are short.\n",
    "- Faster than local approach\n",
    "- Empirically shown to outperform local models (e.g. M5 forecasting competition)\n",
    "\n",
    "Note: global models assume the data generating procress for the group of time series is the same or at least similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odsc_utils import load_product_hierarchy\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "\n",
    "y = load_product_hierarchy()\n",
    "\n",
    "y_train, y_test = temporal_train_test_split(y_hier, test_size=4)\n",
    "\n",
    "y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by using local forecasting with the gradient boosting regressor we used previously to forecast the hierarchical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = HistGradientBoostingRegressor()\n",
    "forecaster = make_reduction(regressor, strategy=\"direct\", window_length=12, pooling=\"local\")\n",
    "\n",
    "y_pred = forecaster.fit_predict(y_train, fh=[1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.forecasters_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can adapt the error metrics to a hierarchical setting by using `multilevel` argument to obtain scores for each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier_smape = MeanAbsolutePercentageError(symmetric=True, multilevel=\"raw_values\")\n",
    "errors_local = hier_smape(y_test, y_pred)\n",
    "errors_local"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the same regressor, we do global forecasting by setting the `pooling` argument to `global`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = HistGradientBoostingRegressor()\n",
    "forecaster = make_reduction(regressor, strategy=\"direct\", window_length=12, pooling=\"global\")\n",
    "\n",
    "y_pred = forecaster.fit_predict(y_train, fh=[1, 2, 3, 4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the scores for the `local` and `global` approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_global = hier_smape(y_test, y_pred)\n",
    "\n",
    "print(f\"Average sMAPE with local pooling: {errors_local.mean().iloc[0]:.1%}\")\n",
    "print(f\"Average sMAPE with global pooling: {errors_global.mean().iloc[0]:.1%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick recap of what we have covered in this notebook:\n",
    "\n",
    "- Univariate forecasting (stats and ML)\n",
    "- Univariate with exogenous data\n",
    "- Multivariate forecasting\n",
    "- Probabilistic forecasting\n",
    "- Hierarchical forecasting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits: notebook 3 - forecasting\n",
    "\n",
    "notebook creation: marrov, fkiraly\n",
    "\n",
    "partly based on:\n",
    "\n",
    "* pydata 2022 Berlin notebooks (fkiraly, danbartl)\n",
    "* sktime forecasting tutorial (fkiraly, mloning and others)\n",
    "\n",
    "sktime forecasting module: [many contributors](https://www.sktime.net/en/latest/about/contributors.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata_sktime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
